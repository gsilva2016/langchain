{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a991a6f8-1897-4f49-a191-ae3bdaeda856",
   "metadata": {},
   "source": [
    "# OpenAI Text2Speech\n",
    "\n",
    "This notebook shows how to interact with the `OpenAI Speech API` to achieve text-to-speech capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb311e-e1bd-4959-8536-4d267f302eb3",
   "metadata": {},
   "source": [
    "First, you need to install required dependencies. In order to make requests to an OpenAI Speech API compatible server one option is to follow the instructions at [Kokoro-FastAPI](https://github.com/remsky/Kokoro-FastAPI) under Quickest Start (docker run) section. This will ensure 'http://localhost:8880/v1' is available for accepting the Text2Speech requests from this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a309c0e-5310-4eaa-8af9-bcbc252e45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update && apt install -y portaudio19-dev build-essential ffmpeg",
    "\n",
    "%pip install --upgrade --quiet openai pyaudio ipython langchain_community langchain-openai torchaudio transformers sounddevice soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b2454-2bff-484d-822c-4026a9dc1383",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57a647-9214-4562-a8cf-f263a15d1f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openai_text2speech'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import OpenAIText2SpeechTool\n",
    "\n",
    "text_to_speak = \"Hello world!\"\n",
    "\n",
    "tts = OpenAIText2SpeechTool(model_id=\"kokoro\", voice=\"af_sky+af_bella\", base_url=\"http://localhost:8880/v1\", api_key=\"not-needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4613fed-66f0-47c6-be50-7e7670654427",
   "metadata": {},
   "source": [
    "We can generate audio, stream and play or save it to the temporary file and then play it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1984844-aa75-4f83-9d42-1c8052d87cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file = tts.run(text_to_speak)\n",
    "tts.play(speech_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d89cd4-ac2a-4857-9787-c9018b4a8782",
   "metadata": {},
   "source": [
    "Or stream audio directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72822f8-3223-47e2-8d2e-6ff46b8c8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts.stream_speech(text_to_speak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152766d-5f06-48b1-ac89-b4e8d88d3c9f",
   "metadata": {},
   "source": [
    "## Use within an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37626aea-0cf0-4849-9c00-c0f40515ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168f28e-d5b7-4c93-bed8-0ab317b4a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"openai_text2speech\"])\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336bf95a-3ccb-4963-aac3-638a4df2ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"openai_labs_text2speech\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"Why did the chicken cross the playground? To get to the other slide!\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m/tmp/tmpsfg783f1.wav\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have the audio file ready to be sent to the human\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"/tmp/tmpsfg783f1.wav\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "audio_file = agent.run(\"Tell me a joke and read it out for me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa7aa9-4682-4599-8cae-59347d9e5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts.play(audio_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
