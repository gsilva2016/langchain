{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48afb8d",
   "metadata": {
    "id": "e48afb8d"
   },
   "source": [
    "# Local Video Ingestion for VLM summarization\n",
    "\n",
    "Building video summarization or QA applications on you're local videos is a topic of high interest. Current Large Vision Language models (VLMs) can only utilize a finite set of frames to represent any given video - this is usually between 8 and 64 frames sampled from an input video, but varies by model. This means that for accurate transcription of long form videos, a chunking mechanism is required to trim videos into smaller clips such that the finite set of frames better represents the video that is being used as visual input to the VLM.\n",
    "\n",
    "Below we show how to easily go from an `.mp4` file to chunked clips used for more accurate LVM video summarizations that can used in downstream tasks including RAG applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34e934",
   "metadata": {
    "id": "5f34e934"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.video import VideoChunkLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e119f4",
   "metadata": {
    "id": "b0e119f4"
   },
   "source": [
    "### Load and chunk local video using the sliding window chunking scheme\n",
    "\n",
    "Use `wget` to fetch / download the sample video file.\n",
    "\n",
    "Then, uses `VideoChunkLoader()` to chunk the video sytematically.\n",
    "\n",
    "Let's take a look at the sample video first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1e134",
   "metadata": {
    "id": "23e1e134",
    "outputId": "0794ffeb-f912-48cc-e3cb-3b4d6e5221c7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-01 14:23:45--  https://github.com/intel-iot-devkit/sample-videos/raw/master/store-aisle-detection.mp4\n",
      "140.82.112.4thub.com (github.com)... \n",
      "connected. to github.com (github.com)|140.82.112.4|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/store-aisle-detection.mp4 [following]\n",
      "--2025-03-01 14:23:46--  https://raw.githubusercontent.com/intel-iot-devkit/sample-videos/master/store-aisle-detection.mp4\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9214573 (8.8M) [application/octet-stream]\n",
      "Saving to: ‘sample_video.mp4’\n",
      "\n",
      "sample_video.mp4    100%[===================>]   8.79M  34.7MB/s    in 0.3s    \n",
      "\n",
      "2025-03-01 14:23:46 (34.7 MB/s) - ‘sample_video.mp4’ saved [9214573/9214573]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"sample_video.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -O sample_video.mp4 https://github.com/intel-iot-devkit/sample-videos/raw/master/store-aisle-detection.mp4\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "video_path = \"sample_video.mp4\"\n",
    "Video(video_path, width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be6b49",
   "metadata": {
    "id": "93be6b49"
   },
   "source": [
    "## Building a video summarization app from local sample video\n",
    "\n",
    "Given `sample_video.mp4`, we can enable ingestion meant for video summarization. Below we will show the two different ingestion mechanisms provided by VideoChunkLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11f4d6-2fec-4945-a9d9-1f12cc334876",
   "metadata": {},
   "source": [
    "### Example of \"Sliding Window\" with overlap implementation\n",
    "\n",
    "To overcome the issue of losing context at start and end of clips, we allow the user to configure a sliding window techinique that includes an overlap to address the missing context at clip start/endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33648d9d-b92d-487a-9ec4-977f05a2c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk metadata: {'chunk_id': 0, 'chunk_path': 'video_chunks/chunk_0.mp4', 'start_time': 0, 'end_time': 10, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 0s to 10s\n",
      "Chunk metadata: {'chunk_id': 1, 'chunk_path': 'video_chunks/chunk_1.mp4', 'start_time': 8, 'end_time': 18, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 8s to 18s\n",
      "Chunk metadata: {'chunk_id': 2, 'chunk_path': 'video_chunks/chunk_2.mp4', 'start_time': 16, 'end_time': 26, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 16s to 26s\n",
      "Chunk metadata: {'chunk_id': 3, 'chunk_path': 'video_chunks/chunk_3.mp4', 'start_time': 24, 'end_time': 34, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 24s to 34s\n",
      "Chunk metadata: {'chunk_id': 4, 'chunk_path': 'video_chunks/chunk_4.mp4', 'start_time': 32, 'end_time': 42, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 32s to 42s\n",
      "Chunk metadata: {'chunk_id': 5, 'chunk_path': 'video_chunks/chunk_5.mp4', 'start_time': 40, 'end_time': 50, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 40s to 50s\n",
      "Chunk metadata: {'chunk_id': 6, 'chunk_path': 'video_chunks/chunk_6.mp4', 'start_time': 48, 'end_time': 58, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 48s to 58s\n",
      "Chunk metadata: {'chunk_id': 7, 'chunk_path': 'video_chunks/chunk_7.mp4', 'start_time': 56, 'end_time': 65.415375, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 56s to 65.415375s\n",
      "Chunk metadata: {'chunk_id': 8, 'chunk_path': 'video_chunks/chunk_8.mp4', 'start_time': 64, 'end_time': 65.415375, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 64s to 65.415375s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"video_chunks/chunk_0.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup VideoChunkLoader object for ingesting video, using the sliding window technique\n",
    "loader = VideoChunkLoader(\n",
    "    video_path=video_path,\n",
    "    chunking_mechanism=\"sliding_window\",\n",
    "    chunk_duration=10,\n",
    "    chunk_overlap=2,\n",
    ")\n",
    "\n",
    "# Display the langchain documents created after loading the sample video, the video chunks are saved in the 'video_chunks' directory\n",
    "for doc in loader.lazy_load():\n",
    "    print(f\"Chunk metadata: {doc.metadata}\")\n",
    "    print(f\"Chunk content: {doc.page_content}\")\n",
    "\n",
    "# Playback of the first interval chunked video, should have length 'chunk_duration'\n",
    "Video(\"video_chunks/chunk_0.mp4\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb2bdc-d554-4de6-9f39-ca8de708e60d",
   "metadata": {},
   "source": [
    "### Example of \"Specific Intervals\" implementation\n",
    "\n",
    "To overcome the issue of many video-summarization workloads that only require summarization of selective parts of the video, we allow the user to pass pre-defined time intervals into the configuration such that only specific portions of the video are chunked, and then used in downstream summarization workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06690c16-6137-4234-a33b-606a27765012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk metadata: {'chunk_id': 0, 'chunk_path': 'video_chunks/chunk_0.mp4', 'start_time': 10, 'end_time': 20, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 10s to 20s\n",
      "Chunk metadata: {'chunk_id': 1, 'chunk_path': 'video_chunks/chunk_1.mp4', 'start_time': 20, 'end_time': 28, 'source': 'sample_video.mp4'}\n",
      "Chunk content: Video chunk from 20s to 28s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"video_chunks/chunk_0.mp4\" controls  width=\"600\"  height=\"400\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup VideoChunkLoader object for ingesting video, using the specific itervals technique\n",
    "loader = VideoChunkLoader(\n",
    "    video_path=video_path,\n",
    "    chunking_mechanism=\"specific_chunks\",\n",
    "    specific_intervals=[{\"start\": 10, \"duration\": 10}, {\"start\": 20, \"duration\": 8}],\n",
    ")\n",
    "\n",
    "# Display the langchain documents created after loading the sample video, the video chunks are saved in the 'video_chunks' directory\n",
    "for doc in loader.lazy_load():\n",
    "    print(f\"Chunk metadata: {doc.metadata}\")\n",
    "    print(f\"Chunk content: {doc.page_content}\")\n",
    "\n",
    "# Playback of the first interval chunked video, should have length 'duration' from first interval\n",
    "Video(\"video_chunks/chunk_0.mp4\", width=600, height=400)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
